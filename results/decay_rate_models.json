{
    "decay_rates": {
        "Human": [
            -50,
            4.04,
            -3.34,
            -3.34,
            -3.34,
            9.58,
            -3.34,
            -3.34,
            -3.34
        ],
        "GPT-4": [
            -50,
            "3.66",
            "3.0",
            "4.55",
            "-0.65",
            "14.71",
            "2.68",
            "10.24",
            "27.64"
        ],
        "GPT-3.5-Turbo": [
            -50,
            "5.57",
            "4.43",
            "15.35",
            "-0.81",
            "34.19",
            "15.55",
            "25.03",
            "35.74"
        ],
        "Mistral-7B": [
            -50,
            "11.12",
            "9.2",
            "24.53",
            "2.3",
            "63.62",
            "29.13",
            "45.02",
            "86.03"
        ],
        "LLaMA-2-7B": [
            -50,
            "3.43",
            "25.41",
            "22.58",
            "-3.95",
            "77.42",
            "43.52",
            "47.47",
            "100.0"
        ],
        "LLaMA-2-13B": [
            -50,
            "-2.09",
            "9.84",
            "30.16",
            "-7.76",
            "62.68",
            "39.41",
            "47.17",
            "98.82"
        ],
        "LLaMA-2-70B": [
            -50,
            "6.01",
            "6.42",
            "25.8",
            "0.26",
            "44.38",
            "17.39",
            "35.43",
            "99.47"
        ],
        "CodeLlama-7B": [
            -50,
            "11.97",
            "5.96",
            "24.53",
            "-2.41",
            "66.15",
            "55.09",
            "63.15",
            "94.31"
        ],
        "CodeLlama-34B": [
            -50,
            "35.21",
            "34.38",
            "38.21",
            "24.08",
            "68.1",
            "63.45",
            "66.28",
            "90.36"
        ],
        "MAmmoTH-Coder-34B": [
            -50,
            "11.22",
            "4.51",
            "20.46",
            "-1.99",
            "41.34",
            "28.43",
            "38.3",
            "100.0"
        ],
        "MAmmoTH-Coder-13B": [
            -50,
            "8.54",
            "4.44",
            "22.54",
            "1.63",
            "43.11",
            "33.42",
            "44.28",
            "100.0"
        ],
        "MAmmoTH-Coder-7B": [
            -50,
            "8.48",
            "5.44",
            "23.54",
            "2.4",
            "51.51",
            "43.8",
            "47.47",
            "100.0"
        ],
        "MAmmoTH-70B": [
            -50,
            "11.19",
            "5.59",
            "21.98",
            "0.5",
            "37.07",
            "25.38",
            "35.26",
            "100.0"
        ],
        "MAmmoTH-13B": [
            -50,
            "12.04",
            "6.2",
            "22.0",
            "0.85",
            "49.7",
            "40.59",
            "45.32",
            "100.0"
        ],
        "MAmmoTH-7B": [
            -50,
            "14.48",
            "6.74",
            "27.69",
            "2.01",
            "59.39",
            "53.8",
            "49.36",
            "100.0"
        ],
        "MetaMath-7B": [
            -50,
            "11.36",
            "11.93",
            "25.57",
            "2.73",
            "53.75",
            "45.01",
            "25.57",
            "92.27"
        ],
        "SEGO-7B": [
            -50,
            "12.14",
            "6.41",
            "24.72",
            "2.1",
            "47.79",
            "45.8",
            "40.28",
            "100.0"
        ],
        "SEGO-13B": [
            -50,
            "9.66",
            "5.46",
            "19.16",
            "1.28",
            "39.88",
            "43.94",
            "36.63",
            "100.0"
        ],
        "MetaMath-Mistral": [
            -50,
            "8.68",
            "10.04",
            "20.38",
            "0.4",
            "42.01",
            "28.46",
            "25.25",
            "86.36"
        ],
        "MetaMath-13B": [
            -50,
            "13.16",
            "9.21",
            "24.94",
            "-1.19",
            "48.71",
            "39.4",
            "23.88",
            "93.04"
        ],
        "MetaMath-70B": [
            -50,
            "8.77",
            "9.23",
            "20.87",
            "3.04",
            "37.86",
            "24.56",
            "29.36",
            "87.81"
        ],
        "CodeLlama-13B": [
            -50,
            "17.72",
            "16.67",
            "21.54",
            "3.59",
            "59.49",
            "53.59",
            "57.18",
            "87.76"
        ],
        "Abel-7B": [
            -50,
            "5.73",
            "14.38",
            "35.15",
            "1.39",
            "58.6",
            "44.08",
            "43.69",
            "98.34"
        ],
        "Abel-13B": [
            -50,
            "6.47",
            "10.46",
            "25.12",
            "-0.9",
            "47.84",
            "31.82",
            "37.62",
            "97.27"
        ],
        "Abel-70B": [
            -50,
            "8.59",
            "8.31",
            "24.14",
            "2.89",
            "36.61",
            "22.7",
            "28.38",
            "96.47"
        ],
        "ToRA-7B": [
            -50,
            "8.09",
            "3.94",
            "19.78",
            "-1.11",
            "52.25",
            "61.47",
            "38.66",
            "100.0"
        ],
        "ToRA-13B": [
            -50,
            "8.98",
            "5.5",
            "21.02",
            "-1.27",
            "44.46",
            "51.64",
            "36.23",
            "100.0"
        ]
    },
    "accuracies": {
        "Human": [
            96.77,
            92.86,
            100,
            100,
            100,
            87.5,
            100,
            100,
            100
        ],
        "GPT-4": [
            93.25,
            89.84,
            90.45,
            89.01,
            93.86,
            79.53,
            90.75,
            83.7,
            67.48
        ],
        "GPT-3.5-Turbo": [
            73.62,
            69.52,
            70.36,
            62.32,
            74.22,
            48.45,
            62.17,
            55.19,
            47.31
        ],
        "Mistral-7B": [
            39.58,
            35.18,
            35.94,
            29.87,
            38.67,
            14.4,
            28.05,
            21.76,
            5.53
        ],
        "LLaMA-2-7B": [
            13.42,
            12.96,
            10.01,
            10.39,
            13.95,
            3.03,
            7.58,
            7.05,
            0.0
        ],
        "LLaMA-2-13B": [
            25.4,
            25.93,
            22.9,
            17.74,
            27.37,
            9.48,
            15.39,
            13.42,
            0.3
        ],
        "LLaMA-2-70B": [
            56.71,
            53.3,
            53.07,
            42.08,
            56.56,
            31.54,
            46.85,
            36.62,
            0.3
        ],
        "CodeLlama-7B": [
            25.32,
            22.29,
            23.81,
            19.11,
            25.93,
            8.57,
            11.37,
            9.33,
            1.44
        ],
        "CodeLlama-34B": [
            45.64,
            29.57,
            29.95,
            28.2,
            34.65,
            14.56,
            16.68,
            15.39,
            4.4
        ],
        "MAmmoTH-Coder-34B": [
            72.25,
            64.14,
            68.99,
            57.47,
            73.69,
            42.38,
            51.71,
            44.58,
            0.0
        ],
        "MAmmoTH-Coder-13B": [
            64.9,
            59.36,
            62.02,
            50.27,
            63.84,
            36.92,
            43.21,
            36.16,
            0.0
        ],
        "MAmmoTH-Coder-7B": [
            59.89,
            54.81,
            56.63,
            45.79,
            58.45,
            29.04,
            33.66,
            31.46,
            0.0
        ],
        "MAmmoTH-70B": [
            75.89,
            67.4,
            71.65,
            59.21,
            75.51,
            47.76,
            56.63,
            49.13,
            0.0
        ],
        "MAmmoTH-13B": [
            62.4,
            54.89,
            58.53,
            48.67,
            61.87,
            31.39,
            37.07,
            34.12,
            0.0
        ],
        "MAmmoTH-7B": [
            52.84,
            45.19,
            49.28,
            38.21,
            51.78,
            21.46,
            24.41,
            26.76,
            0.0
        ],
        "MetaMath-7B": [
            66.72,
            59.14,
            58.76,
            49.66,
            64.9,
            30.86,
            36.69,
            49.66,
            5.16
        ],
        "SEGO-7B": [
            68.69,
            60.35,
            64.29,
            51.71,
            67.25,
            35.86,
            37.23,
            41.02,
            0.0
        ],
        "SEGO-13B": [
            72.5,
            65.5,
            68.54,
            58.61,
            71.57,
            43.59,
            40.64,
            45.94,
            0.0
        ],
        "MetaMath-Mistral": [
            77.79,
            71.04,
            69.98,
            61.94,
            77.48,
            45.11,
            55.65,
            58.15,
            10.61
        ],
        "MetaMath-13B": [
            70.81,
            61.49,
            64.29,
            53.15,
            71.65,
            36.32,
            42.91,
            53.9,
            4.93
        ],
        "MetaMath-70B": [
            82.11,
            74.91,
            74.53,
            64.97,
            79.61,
            51.02,
            61.94,
            58.0,
            10.01
        ],
        "CodeLlama-13B": [
            35.94,
            29.57,
            29.95,
            28.2,
            34.65,
            14.56,
            16.68,
            15.39,
            4.4
        ],
        "Abel-7B": [
            59.51,
            56.1,
            50.95,
            38.59,
            58.68,
            24.64,
            33.28,
            33.51,
            0.99
        ],
        "Abel-13B": [
            66.72,
            62.4,
            59.74,
            49.96,
            67.32,
            34.8,
            45.49,
            41.62,
            1.82
        ],
        "Abel-70B": [
            83.85,
            76.65,
            76.88,
            63.61,
            81.43,
            53.15,
            64.82,
            60.05,
            2.96
        ],
        "ToRA-7B": [
            67.48,
            62.02,
            64.82,
            54.13,
            68.23,
            32.22,
            26.0,
            41.39,
            0.0
        ],
        "ToRA-13B": [
            71.8,
            65.35,
            67.85,
            56.71,
            72.71,
            39.88,
            34.72,
            45.79,
            0.0
        ]
    }
}